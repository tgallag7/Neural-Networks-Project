{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tgallag7/Neural-Networks-Project\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmcRAqYtj-kU",
        "outputId": "312420c3-9f50-4679-ab57-a7e07bb11a7c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Neural-Networks-Project'...\n",
            "remote: Enumerating objects: 351, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 351 (delta 7), reused 84 (delta 6), pack-reused 258\u001b[K\n",
            "Receiving objects: 100% (351/351), 87.52 MiB | 25.17 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Bf5hY-MdFXe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR100, CIFAR10\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.transforms.functional import resize\n",
        "from torchvision.transforms import CenterCrop\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from PIL import Image\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Siamese(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Siamese, self).__init__()\n",
        "\n",
        "    # Convolutional layers:\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=96, kernel_size=(11,11), stride=(4,4))\n",
        "    self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=(5,5), stride=(1,1))\n",
        "    self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=(3,3), stride=(1,1))\n",
        "    self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=(3,3), stride=(1,1))\n",
        "    self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=(3,3), stride=(1,1))\n",
        "\n",
        "    # Activation function:\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    # Pooling layer:\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "\n",
        "    # Batch normalization layers:\n",
        "    self.batchnorm1 = nn.BatchNorm2d(num_features=96)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(num_features=256)\n",
        "\n",
        "    # Fully-connected layers:\n",
        "    self.fc1 = nn.Linear(in_features=1024, out_features=1024)\n",
        "    self.fc2 = nn.Linear(in_features=1024, out_features=10)\n",
        "\n",
        "  #Helper function that will be called to forward an individual object\n",
        "  def forwardHelper(self, x):\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.batchnorm1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.batchnorm2(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv4(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  #Forward 2 objects, 1 for each inputted image\n",
        "  def forward(self, x1, x2):\n",
        "    x1 = self.forwardHelper(x1)\n",
        "    x2 = self.forwardHelper(x2)\n",
        "    return (x1,x2)\n",
        "\n",
        "\n",
        "  def evaluate(self, model, dataloader, classes, device):\n",
        "    # We need to switch the model into the evaluation mode\n",
        "    model.eval()\n",
        "        \n",
        "    # Prepare to count predictions for each class\n",
        "    correct_pred = {classname: 0 for classname in classes}\n",
        "    total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "    crit = ContrastiveLoss()\n",
        "\n",
        "    # For all test data samples:\n",
        "    for data in dataloader:\n",
        "        image1, image2, label = data\n",
        "        image1 = image1.to(device)\n",
        "        image2 = image2.to(device)\n",
        "        label = label.to(device)\n",
        "        output1, output2 = model(image1, image2)\n",
        "\n",
        "        loss = torch.sum(torch.nn.functional.pairwise_distance(image1, image2))\n",
        "\n",
        "        image1 = image1.detach().cpu().numpy()\n",
        "        image2 = image2.detach().cpu().numpy()\n",
        "        label = label.detach().cpu().numpy()\n",
        "\n",
        "        #Convert loss into prediction\n",
        "        #prediction of 0 means real, prediction of 1 means fake\n",
        "        if loss < 0.5:\n",
        "          pred = 0\n",
        "        else:\n",
        "          pred = 1\n",
        "\n",
        "        # Count the correct predictions for each class\n",
        "        if int(label) == pred:\n",
        "          correct_pred[classes[int(label)]] += 1\n",
        "        total_pred[classes[int(label)]] += 1\n",
        "\n",
        "\n",
        "    # Calculate the overall accuracy on the test set\n",
        "    acc = sum(correct_pred.values()) / sum(total_pred.values())\n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "id": "YA8HRPqIoJVG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Used to convert each image to 8 bit image\n",
        "def pixelate(imgPath, size):\n",
        "  image = Image.open(imgPath)\n",
        "  image = image.convert(\"L\")\n",
        "  \n",
        "  image = image.resize((224,224))\n",
        "\n",
        "  image.save(imgPath)\n",
        "  image.close()\n"
      ],
      "metadata": {
        "id": "FCkuwGwOnSX0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This piece of the code prepares images and labels stored \n",
        "# in GitHub to be usable in Pytorch.\n",
        "\n",
        "class SignatureImages(Dataset):\n",
        "    def __init__(self, img_dir, label_dir, transform):\n",
        "        self.img_dir = img_dir\n",
        "        self.img_labels = pd.read_csv(label_dir, header=0)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path1 = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        img_path2 = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
        "\n",
        "        #Resizes images and saves them in current path\n",
        "        pixelate(img_path1, 8)\n",
        "        pixelate(img_path2, 8)\n",
        "\n",
        "        image1 = read_image(img_path1)\n",
        "        image1 = image1.to(torch.float) / 256.\n",
        "\n",
        "        image2 = read_image(img_path1)\n",
        "        image2 = image2.to(torch.float) / 256.\n",
        "\n",
        "        label = self.img_labels.iloc[idx, 2]\n",
        "        if self.transform:\n",
        "            image1 = self.transform(image1)\n",
        "            image2 = self.transform(image2)\n",
        "\n",
        "        return (image1, image2, label)\n",
        "\n",
        "# Transform images:\n",
        "# a) to tensor: convert the PIL image or numpy.ndarray to tensor\n",
        "# b) Z-normalize a tensor image (using its mean and standard deviation\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "\n",
        "# Path to the  dataset:\n",
        "image_dir = \"Neural-Networks-Project/images/\"\n",
        "\n",
        "# Path to the labels of the signatures in the dataset\n",
        "label_dir = \"Neural-Networks-Project/labels.csv\""
      ],
      "metadata": {
        "id": "cNwxHkPzLmGL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "batch_size = 1"
      ],
      "metadata": {
        "id": "Zn2j8d36l2H7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(10)\n",
        "\n",
        "# Load signature dataset\n",
        "data = SignatureImages(img_dir=image_dir, label_dir=label_dir, transform=transforms.Normalize((0.5), (0.5)))\n",
        "train_len = int(len(data) * 0.6)\n",
        "val_len = int(len(data) * 0.2)\n",
        "test_len = int(len(data) - train_len - val_len)\n",
        "train_data, val_data, test_data = random_split(data, [train_len, val_len, test_len])\n",
        "classes = ['genuine', 'forged']\n",
        "\n",
        "# Prepare data loaders for train, validation and test data splits \n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2)"
      ],
      "metadata": {
        "id": "GQUHu8ZxljWf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Criterion for loss function\n",
        "class ContrastiveLoss(nn.Module):\n",
        "  def __init__(self, margin=2.0):\n",
        "    super(ContrastiveLoss, self).__init__()\n",
        "    self.margin = margin\n",
        "\n",
        "  #Utilize Euclidean Distance to find similarity between 2 images\n",
        "  def forward(self, output1, output2, label):\n",
        "    euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
        "    pos = (1-label) * torch.pow(euclidean_distance, 2)\n",
        "    neg = (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
        "    loss = torch.mean( pos + neg )\n",
        "    return loss"
      ],
      "metadata": {
        "id": "l52tQ_TtXYUP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Set the device (GPU or CPU, depending on availability)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"Currently using device: \", device)\n",
        "\n",
        "    # Initialize the model and print out its configuration\n",
        "    model = Siamese()\n",
        "    model.to(device)\n",
        "\n",
        "    print(\"\\n\\nModel summary:\\n\\n\")\n",
        "    summary(model,[(1,224,224),(1,224,224)],batch_size = 1)\n",
        "\n",
        "    print(\"\\n\\nTraining starts!\\n\\n\")\n",
        "        \n",
        "    model.train()\n",
        "    criterion = ContrastiveLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        \n",
        "    running_loss = .0\n",
        "    best_acc = .0\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Starting epoch {epoch + 1}\")\n",
        "        for idx, data in tqdm(enumerate(train_data), total=len(train_data)):\n",
        "            # Get the inputs (data is a list of [image1, image2, labels])\n",
        "            image1, image2, label = data\n",
        "            image1 = image1.to(device).reshape(1,1,224,224)\n",
        "            image2 = image2.to(device).reshape(1,1,224,224)\n",
        "            optimizer.zero_grad()\n",
        "            output1, output2 = model(image1, image2)\n",
        "            loss = criterion(output1, output2, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss = loss.detach().cpu().numpy()\n",
        "            image1 = image1.detach().cpu().numpy()\n",
        "            image2 = image2.detach().cpu().numpy()\n",
        "            running_loss += loss\n",
        "\n",
        "        # Evaluate the accuracy after each epoch\n",
        "        acc = model.evaluate(model, train_loader, classes, device)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            torch.save(model.state_dict(), \"model.pt\")\n",
        "\n",
        "    print(f\"Best accuracy: {best_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HULGHMmet22H",
        "outputId": "571abaf7-e110-40a1-ff52-37899db80f61"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently using device:  cpu\n",
            "\n",
            "\n",
            "Model summary:\n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [1, 96, 54, 54]          11,712\n",
            "              ReLU-2            [1, 96, 54, 54]               0\n",
            "         MaxPool2d-3            [1, 96, 27, 27]               0\n",
            "       BatchNorm2d-4            [1, 96, 27, 27]             192\n",
            "            Conv2d-5           [1, 256, 23, 23]         614,656\n",
            "              ReLU-6           [1, 256, 23, 23]               0\n",
            "         MaxPool2d-7           [1, 256, 11, 11]               0\n",
            "       BatchNorm2d-8           [1, 256, 11, 11]             512\n",
            "            Conv2d-9             [1, 384, 9, 9]         885,120\n",
            "             ReLU-10             [1, 384, 9, 9]               0\n",
            "           Conv2d-11             [1, 384, 7, 7]       1,327,488\n",
            "             ReLU-12             [1, 384, 7, 7]               0\n",
            "           Conv2d-13             [1, 256, 5, 5]         884,992\n",
            "             ReLU-14             [1, 256, 5, 5]               0\n",
            "        MaxPool2d-15             [1, 256, 2, 2]               0\n",
            "           Linear-16                  [1, 1024]       1,049,600\n",
            "             ReLU-17                  [1, 1024]               0\n",
            "           Linear-18                    [1, 10]          10,250\n",
            "           Conv2d-19            [1, 96, 54, 54]          11,712\n",
            "             ReLU-20            [1, 96, 54, 54]               0\n",
            "        MaxPool2d-21            [1, 96, 27, 27]               0\n",
            "      BatchNorm2d-22            [1, 96, 27, 27]             192\n",
            "           Conv2d-23           [1, 256, 23, 23]         614,656\n",
            "             ReLU-24           [1, 256, 23, 23]               0\n",
            "        MaxPool2d-25           [1, 256, 11, 11]               0\n",
            "      BatchNorm2d-26           [1, 256, 11, 11]             512\n",
            "           Conv2d-27             [1, 384, 9, 9]         885,120\n",
            "             ReLU-28             [1, 384, 9, 9]               0\n",
            "           Conv2d-29             [1, 384, 7, 7]       1,327,488\n",
            "             ReLU-30             [1, 384, 7, 7]               0\n",
            "           Conv2d-31             [1, 256, 5, 5]         884,992\n",
            "             ReLU-32             [1, 256, 5, 5]               0\n",
            "        MaxPool2d-33             [1, 256, 2, 2]               0\n",
            "           Linear-34                  [1, 1024]       1,049,600\n",
            "             ReLU-35                  [1, 1024]               0\n",
            "           Linear-36                    [1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 9,569,044\n",
            "Trainable params: 9,569,044\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 9604.00\n",
            "Forward/backward pass size (MB): 17.52\n",
            "Params size (MB): 36.50\n",
            "Estimated Total Size (MB): 9658.03\n",
            "----------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training starts!\n",
            "\n",
            "\n",
            "Starting epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:53<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:48<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:46<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:48<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:50<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:48<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:47<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:48<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:48<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:47<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:48<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:48<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:47<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:48<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:47<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:48<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:48<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:47<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 180/180 [00:48<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy: 50.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find accuracy of model run on validation set\n",
        "acc = model.evaluate(model, val_loader, classes, device)\n",
        "print(f\"Accuracy on the validation data: {acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ckzHEa-f8e3",
        "outputId": "502528fa-ebd1-4faa-95be-84f2680f27cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the validation data: 53.33%\n"
          ]
        }
      ]
    }
  ]
}